{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17d6c935",
   "metadata": {},
   "source": [
    "# Medical Machine Translation Dataset Generation (Chinese → Thai)\n",
    "## Google Colab Version with Open-Source Model\n",
    "\n",
    "This notebook adapts the original `generate_dataset.py` script to run in Google Colab and uses an open-source translation model (`Helsinki-NLP/opus-mt-zh-th`) from Hugging Face instead of the DeepSeek API.\n",
    "\n",
    "**Instructions:**\n",
    "1. Run the **Install Dependencies** cell.\n",
    "2. Run the **Imports** cell.\n",
    "3. Run the **Dataset Templates** cell.\n",
    "4. Run the **Hugging Face Model Setup** cell. This will download the model (may take a few minutes).\n",
    "5. Run the **Helper Functions** cells (Translation, Logging, File Utilities).\n",
    "6. Run the **Core Data Generation Logic** cell.\n",
    "7. Run the **Main Script Utilities** cell.\n",
    "8. Configure parameters in the **Colab Parameter Setup and Execution** cell.\n",
    "9. Run the **Colab Parameter Setup and Execution** cell to generate the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ccb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install Dependencies\n",
    "!pip install pandas transformers torch sentencepiece tqdm accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c990e4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Imports\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from tqdm.auto import tqdm  # Use tqdm.auto for notebook compatibility\n",
    "import datetime\n",
    "import string\n",
    "import random as pyrandom\n",
    "import logging\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910012aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Dataset Templates\n",
    "# (Content from dataset_templates.py)\n",
    "\n",
    "MEDICAL_TOPICS = [\n",
    "    {\"zh\": \"感冒\", \"th\": \"ไข้หวัด\", \"desc\": \"普通感冒症状与治疗\"},\n",
    "    {\"zh\": \"高血压\", \"th\": \"ความดันโลหิตสูง\", \"desc\": \"高血压管理与药物\"},\n",
    "    {\"zh\": \"糖尿病\", \"th\": \"โรคเบาหวาน\", \"desc\": \"糖尿病护理与饮食建议\"},\n",
    "    {\"zh\": \"胃痛\", \"th\": \"อาการปวดท้อง\", \"desc\": \"胃部不适与消化问题\"},\n",
    "    {\"zh\": \"头痛\", \"th\": \"อาการปวดศีรษะ\", \"desc\": \"各种类型的头痛及其原因\"},\n",
    "    {\"zh\": \"皮肤过敏\", \"th\": \"โรคภูมิแพ้ผิวหนัง\", \"desc\": \"皮肤过敏症状与治疗\"},\n",
    "    {\"zh\": \"失眠\", \"th\": \"อาการนอนไม่หลับ\", \"desc\": \"失眠问题与改善方法\"},\n",
    "    {\"zh\": \"关节炎\", \"th\": \"โรคข้ออักเสบ\", \"desc\": \"关节炎疼痛与护理\"},\n",
    "    {\"zh\": \"哮喘\", \"th\": \"โรคหอบหืด\", \"desc\": \"哮喘发作与预防\"},\n",
    "    {\"zh\": \"抑郁症\", \"th\": \"โรคซึมเศร้า\", \"desc\": \"抑郁症的心理支持与治疗\"},\n",
    "    {\"zh\": \"骨折\", \"th\": \"กระดูกหัก\", \"desc\": \"骨折处理与康复\"},\n",
    "    {\"zh\": \"肺炎\", \"th\": \"โรคปอดบวม\", \"desc\": \"肺炎症状与治疗方法\"},\n",
    "    {\"zh\": \"心脏病\", \"th\": \"โรคหัวใจ\", \"desc\": \"心脏健康与预防\"},\n",
    "    {\"zh\": \"肾结石\", \"th\": \"โรคนิ่วในไต\", \"desc\": \"肾结石的症状与处理\"},\n",
    "    {\"zh\": \"中风\", \"th\": \"โรคหลอดเลือดสมอง\", \"desc\": \"中风的急救与康复\"},\n",
    "    {\"zh\": \"视力模糊\", \"th\": \"อาการตามัว\", \"desc\": \"视力问题与眼科检查\"},\n",
    "    {\"zh\": \"牙痛\", \"th\": \"อาการปวดฟัน\", \"desc\": \"牙痛原因与牙科治疗\"},\n",
    "    {\"zh\": \"过敏性鼻炎\", \"th\": \"โรคจมูกอักเสบจากภูมิแพ้\", \"desc\": \"过敏性鼻炎的控制与治疗\"},\n",
    "    {\"zh\": \"消化不良\", \"th\": \"อาหารไม่ย่อย\", \"desc\": \"消化不良的症状与饮食调整\"},\n",
    "    {\"zh\": \"烧伤\", \"th\": \"แผลไฟไหม้น้ำร้อนลวก\", \"desc\": \"烧伤处理与皮肤护理\"}\n",
    "]\n",
    "\n",
    "DIALOGUE_SAMPLES = [\n",
    "    {\"context\": \"患者主诉发热、咳嗽三天。\", \"symptom\": \"发热, 咳嗽\", \"source\": \"医生，我这几天感觉很不舒服，发烧还咳嗽，有三天了。体温量了吗？最高多少度？\", \"target\": \"คุณหมอคะ mấy วันนี้รู้สึกไม่สบายเลยค่ะ เป็นไข้แล้วก็ไอด้วย เป็นมา 3 วันแล้วค่ะ วัดไข้ไหมคะ สูงสุดเท่าไหร่คะ?\"},\n",
    "    {\"context\": \"患者咨询高血压药物的副作用。\", \"symptom\": \"高血压, 药物副作用\", \"source\": \"我一直在吃降压药，最近感觉有些头晕乏力，是药物的副作用吗？您吃的具体是什么药？这种药常见的副作用确实包括头晕。\", \"target\": \"ทานยาลดความดันมาตลอด ช่วงนี้รู้สึกเวียนหัว อ่อนเพลีย เป็นผลข้างเคียงของยาหรือเปล่าครับ? คุณทานยาอะไรอยู่ครับ? ยาตัวนี้ผลข้างเคียงที่พบบ่อยก็มีอาการเวียนหัวครับ\"},\n",
    "    {\"context\": \"患者血糖控制不佳，医生调整用药。\", \"symptom\": \"糖尿病, 血糖高\", \"source\": \"我最近测血糖还是偏高，饮食也注意了，是不是药效不够？根据您的情况，我们可能需要调整一下胰岛素的剂量。\", \"target\": \"ช่วงนี้วัดน้ำตาลในเลือดก็ยังสูงอยู่ค่ะ อาหารก็ระวังแล้ว เป็นเพราะยาไม่พอหรือเปล่าคะ? จากอาการของคุณ เราอาจจะต้องปรับขนาดยาอินซูลินหน่อยนะคะ\"},\n",
    "    {\"context\": \"患者胃痛，医生询问饮食习惯。\", \"symptom\": \"胃痛, 饮食不规律\", \"source\": \"医生，我胃痛好几天了，特别是饭后。您平时吃饭规律吗？有没有吃什么刺激性的食物？\", \"target\": \"คุณหมอครับ ผมปวดท้องมาหลายวันแล้ว โดยเฉพาะหลังกินข้าวครับ ปกติคุณทานข้าวตรงเวลามั้ยครับ? ได้ทานอาหารรสจัดอะไรบ้างมั้ยครับ?\"},\n",
    "    {\"context\": \"患者因偏头痛就诊。\", \"symptom\": \"偏头痛\", \"source\": \"我头痛得厉害，感觉是偏头痛又犯了。您描述一下疼痛的性质和位置好吗？\", \"target\": \"ปวดหัวมากเลยค่ะ รู้สึกเหมือนไมเกรนกำเริบอีกแล้ว ช่วยอธิบายลักษณะอาการปวดและตำแหน่งได้ไหมคะ?\"},\n",
    "    {\"context\": \"儿童皮肤出现红疹，怀疑过敏。\", \"symptom\": \"皮肤红疹, 过敏\", \"source\": \"医生您看，我家孩子身上起了好多红疹子，痒得不行，是不是过敏了？最近有没有接触什么新的东西或者吃什么特别的食物？\", \"target\": \"คุณหมอดูสิคะ ลูกฉันมีผื่นแดงขึ้นเต็มตัวเลย คันมาก ไม่รู้ว่าแพ้อะไรรึเปล่าคะ? ช่วงนี้ได้สัมผัสอะไรใหม่ๆ หรือกินอาหารอะไรเป็นพิเศษไหมคะ?\"},\n",
    "    {\"context\": \"患者长期失眠，寻求帮助。\", \"symptom\": \"失眠\", \"source\": \"我最近总是失眠，晚上翻来覆去睡不着，白天没精神。这种情况持续多久了？有没有什么压力或者心事？\", \"target\": \"ช่วงนี้ฉันนอนไม่หลับตลอดเลยค่ะ กลางคืนพลิกตัวไปมานอนไม่หลับ กลางวันก็ไม่มีแรงเลยค่ะ เป็นแบบนี้มานานแค่ไหนแล้วคะ? มีเรื่องเครียดหรือกังวลอะไรไหมคะ?\"},\n",
    "    {\"context\": \"老年患者关节疼痛，咨询治疗方案。\", \"symptom\": \"关节炎, 关节痛\", \"source\": \"医生，我的膝盖关节一到阴雨天就疼得厉害，有什么好办法缓解吗？您这种情况可能是关节炎，我们可以先做个检查确诊一下。\", \"target\": \"คุณหมอคะ ข้อเข่าของฉันพอถึงวันฟ้าครึ้มฝนตกทีไรก็ปวดมากเลยค่ะ มีวิธีบรรเทาดีๆ บ้างไหมคะ? อาการแบบนี้น่าจะเป็นข้ออักเสบนะคะ เราลองตรวจดูก่อนเพื่อยืนยันนะคะ\"},\n",
    "    {\"context\": \"患者哮喘发作，呼吸困难。\", \"symptom\": \"哮喘, 呼吸困难\", \"source\": \"我哮喘又犯了，感觉喘不上气来。赶紧用一下您的急救喷雾，我给您听一下肺部。\", \"target\": \"โรคหอบหืดของฉันกำเริบอีกแล้วค่ะ รู้สึกหายใจไม่ออกเลย รีบใช้ยาพ่นฉุกเฉินของคุณก่อนนะคะ เดี๋ยวหมอขอฟังเสียงปอดหน่อยค่ะ\"},\n",
    "    {\"context\": \"患者情绪低落，怀疑抑郁。\", \"symptom\": \"情绪低落, 抑郁倾向\", \"source\": \"我最近心情一直很差，对什么都提不起兴趣，是不是有点抑郁了？能具体说说您的感受和这种情况持续的时间吗？\", \"target\": \"ช่วงนี้อารมณ์ไม่ดีเลยค่ะ ไม่สนใจอะไรเลย ไม่รู้ว่าเป็นซึมเศร้ารึเปล่าคะ? ช่วยเล่าความรู้สึกของคุณกับระยะเวลาที่เป็นแบบนี้ให้ฟังหน่อยได้ไหมคะ?\"}    \n",
    "]\n",
    "\n",
    "QA_SAMPLES = [\n",
    "    {\"topic\": \"感冒\", \"context\": \"关于普通感冒的常见问题。\", \"question\": \"感冒一般几天能好？\", \"answer\": \"普通感冒通常持续7到10天，但有些症状如咳嗽可能会持续更长时间。\", \"q_th\": \"ไข้หวัดธรรมดากี่วันถึงจะหาย?\", \"a_th\": \"ไข้หวัดธรรมดามักจะหายภายใน 7 ถึง 10 วัน แต่อาการบางอย่างเช่น อาจจะยังคงอยู่นานกว่านั้น\"},\n",
    "    {\"topic\": \"高血压\", \"context\": \"高血压患者的饮食注意事项。\", \"question\": \"高血压患者饮食上要注意什么？\", \"answer\": \"高血压患者应注意低盐、低脂饮食，多吃蔬菜水果，控制体重。\", \"q_th\": \"ผู้ป่วยความดันโลหิตสูงควรระวังอะไรในการรับประทานอาหาร?\", \"a_th\": \"ผู้ป่วยความดันโลหิตสูงควรรับประทานอาหารที่มีเกลือต่ำ ไขมันต่ำ รับประทานผักและผลไม้ให้มาก และควบคุมน้ำหนักตัว\"},\n",
    "    {\"topic\": \"糖尿病\", \"context\": \"糖尿病的典型症状。\", \"question\": \"糖尿病有哪些典型症状？\", \"answer\": \"糖尿病的典型症状包括多饮、多尿、多食和体重减轻，即“三多一少”。\", \"q_th\": \"โรคเบาหวานมีอาการ典型อย่างไรบ้าง?\", \"a_th\": \"อาการทั่วไปของโรคเบาหวาน ได้แก่ ดื่มน้ำมาก ปัสสาวะบ่อย กินจุ และน้ำหนักลด หรือที่เรียกว่า “สามมากหนึ่งน้อย”\"},\n",
    "    {\"topic\": \"胃痛\", \"context\": \"胃痛的可能原因。\", \"question\": \"什么原因可能导致胃痛？\", \"answer\": \"胃痛的可能原因很多，包括消化不良、胃炎、胃溃疡、胃食管反流等。如果胃痛持续或严重，建议就医检查。\", \"q_th\": \"สาเหตุใดบ้างที่อาจทำให้ปวดท้อง?\", \"a_th\": \"สาเหตุของอาการปวดท้องมีได้หลายอย่าง เช่น อาหารไม่ย่อย กระเพาะอาหารอักเสบ แผลในกระเพาะอาหาร กรดไหลย้อน หากปวดท้องต่อเนื่องหรือรุนแรง ควรไปพบแพทย์เพื่อตรวจ\"},\n",
    "    {\"topic\": \"头痛\", \"context\": \"缓解头痛的方法。\", \"question\": \"如何缓解头痛？\", \"answer\": \"缓解头痛的方法因人而异，可以尝试休息、按摩、冷敷或热敷、饮用足够的水。如果头痛频繁或严重，应咨询医生。\", \"q_th\": \"จะบรรเทาอาการปวดหัวได้อย่างไร?\", \"a_th\": \"วิธีบรรเทาอาการปวดหัวแตกต่างกันไปในแต่ละบุคคล ลองพักผ่อน นวด ประคบเย็นหรือประคบร้อน ดื่มน้ำให้เพียงพอ หากปวดหัวบ่อยหรือรุนแรง ควรปรึกษาแพทย์\"}\n",
    "]\n",
    "\n",
    "MEDICAL_REASONING_SAMPLES = [\n",
    "    {\"context\": \"患者，男，65岁，有长期吸烟史，近期出现持续性咳嗽、咳痰带血、胸痛和体重下降。胸部X光片显示肺部有占位性病变。\", \"question\": \"根据患者的病史、症状和影像学检查结果，最可能的诊断是什么？为什么？\", \"answer\": \"最可能的诊断是肺癌。原因如下：1. 患者为老年男性，有长期吸烟史，是肺癌的高危人群。2. 患者的症状如持续性咳嗽、咳痰带血、胸痛和体重下降是肺癌的常见临床表现。3. 胸部X光片显示肺部占位性病变，高度提示恶性肿瘤的可能。\", \"q_th\": \"จากประวัติผู้ป่วย อาการ และผลการตรวจทางรังสีวิทยา การวินิจฉัยที่เป็นไปได้มากที่สุดคืออะไร เพราะเหตุใด?\", \"a_th\": \"การวินิจฉัยที่เป็นไปได้มากที่สุดคือมะเร็งปอด ด้วยเหตุผลดังต่อไปนี้: 1. ผู้ป่วยเป็นชายสูงอายุ มีประวัติสูบบุหรี่มานาน ซึ่งเป็นกลุ่มเสี่ยงสูงของมะเร็งปอด 2. อาการของผู้ป่วย เช่น ไอเรื้อรัง เสมหะปนเลือด เจ็บหน้าอก และน้ำหนักลด เป็นอาการทางคลินิกที่พบบ่อยของมะเร็งปอด 3. ภาพถ่ายรังสีทรวงอกพบก้อนในปอด ซึ่งบ่งชี้อย่างมากถึงความเป็นไปได้ของเนื้องอกร้ายแรง\"},\n",
    "    {\"context\": \"患者，女，30岁，因突发右下腹剧烈疼痛伴恶心、呕吐、发热就诊。体格检查发现右下腹压痛、反跳痛明显，麦氏点压痛阳性。实验室检查白细胞计数及中性粒细胞比例显著升高。\", \"question\": \"结合患者的临床表现和实验室检查结果，应首先考虑哪种急腹症？主要的诊断依据是什么？\", \"answer\": \"应首先考虑急性阑尾炎。主要诊断依据：1. 典型的转移性右下腹疼痛，伴有恶心、呕吐、发热等症状。2. 体格检查发现右下腹固定压痛、反跳痛，麦氏点压痛阳性，这些是急性阑尾炎的典型体征。3. 实验室检查显示白细胞计数和中性粒细胞比例升高，提示存在急性细菌感染。\", \"q_th\": \"จากอาการทางคลินิกและผลการตรวจทางห้องปฏิบัติการของผู้ป่วย ควรพิจารณาภาวะฉุกเฉินในช่องท้องชนิดใดเป็นอันดับแรก และหลักฐานสำคัญในการวินิจฉัยคืออะไร?\", \"a_th\": \"ควรพิจารณาไส้ติ่งอักเสบเฉียบพลันเป็นอันดับแรก หลักฐานสำคัญในการวินิจฉัยคือ: 1. อาการปวดท้องด้านขวาล่างแบบย้ายที่อย่างเฉียบพลัน ร่วมกับอาการคลื่นไส้ อาเจียน และมีไข้ 2. การตรวจร่างกายพบอาการกดเจ็บและปล่อยเจ็บที่ท้องด้านขวาล่างชัดเจน และกดเจ็บที่จุดแมคเบอร์นีย์ ซึ่งเป็นอาการแสดงที่典型ของไส้ติ่งอักเสบเฉียบพลัน 3. ผลการตรวจทางห้องปฏิบัติการพบจำนวนเม็ดเลือดขาวและสัดส่วนนิวโทรฟิลสูงขึ้น ซึ่งบ่งชี้ว่ามีการติดเชื้อแบคทีเรียเฉียบพลัน\"}\n",
    "]\n",
    "\n",
    "SUMMARIZATION_SAMPLES = [\n",
    "    {\"context\": \"患者：医生，我最近总是感觉很累，头也晕晕的，有时候还会心慌。我今年55岁，有高血压病史5年了，一直在吃药控制，但最近感觉效果不太好。医生：您好，您这种情况多久了？除了这些症状，还有没有胸闷、气短的感觉？血压最近测过吗？规律吗？患者：大概有半个多月了吧。有时候会觉得胸口闷闷的，上楼梯会有点喘。血压我每天都测，早上比较高，大概在150/95mmHg左右，下午会好一点。医生：嗯，您这种情况需要重视。高血压控制不佳，加上您描述的症状，我们需要排除一下心脏方面的问题。我建议您先做一个心电图和心脏彩超检查，看看心脏结构和功能有没有异常。另外，我们可能需要调整一下您的降压药物。您目前在服用什么药物？剂量是多少？患者：我现在吃的是硝苯地平缓释片，一天一次，一次一片。医生：好的，了解了。我们先做检查，根据检查结果再制定下一步的治疗方案。平时饮食注意低盐低脂，保持情绪稳定，适当活动，但不要剧烈运动。\", \"summary_zh\": \"患者为55岁男性，有5年高血压病史，近期感乏力、头晕、心慌半月余，伴胸闷、活动后气短。晨起血压较高（150/95mmHg）。目前服用硝苯地平缓释片控制血压。医生怀疑心脏问题，建议行心电图、心脏彩超检查，并可能调整降压药物。嘱患者低盐低脂饮食，稳定情绪，适当活动。\", \"summary_th\": \"ผู้ป่วยชายอายุ 55 ปี มีประวัติความดันโลหิตสูง 5 ปี ช่วงครึ่งเดือนที่ผ่านมารู้สึกอ่อนเพลีย เวียนศีรษะ ใจสั่น ร่วมกับแน่นหน้าอก หายใจลำบากเมื่อออกแรง ความดันโลหิตตอนเช้าค่อนข้างสูง (150/95 mmHg) ปัจจุบันรับประทานยา Nifedipine SR เพื่อควบคุมความดัน แพทย์สงสัยปัญหาเกี่ยวกับหัวใจ แนะนำให้ตรวจคลื่นไฟฟ้าหัวใจและอัลตราซาวนด์หัวใจ และอาจปรับยา ลดความดันโลหิต แนะนำให้ผู้ป่วยรับประทานอาหารเค็มน้อยไขมันต่ำ ควบคุมอารมณ์ และออกกำลังกายพอประมาณ\"},\n",
    "    {\"context\": \"患者：医生，我孩子最近老是咳嗽，晚上尤其厉害，有时候咳得都睡不好觉。也没发烧，就是咳。医生：您好，孩子这种情况多久了？咳嗽有痰吗？是什么颜色的痰？有没有鼻塞流涕或者其他不舒服？患者：大概一周多了。开始是干咳，这两天有点痰，白色的黏痰。鼻子好像有点塞，偶尔打喷嚏。精神状态还可以，就是玩的时候容易咳。医生：好的。根据您描述的情况，孩子可能是上呼吸道感染或者支气管炎初期。晚上咳嗽加重，白色黏痰，需要注意一下。我建议先给孩子查一个血常规，看看有没有细菌感染的指征。另外，可以做个雾化治疗帮助化痰止咳。饮食上注意清淡，多喝水，避免去人多的地方，以免交叉感染。\", \"summary_zh\": \"患儿咳嗽一周余，夜间为甚，初为干咳，后有白色黏痰，伴鼻塞、偶有喷嚏，无发热。医生初步考虑上呼吸道感染或支气管炎初期，建议查血常规，行雾化治疗，并嘱清淡饮食、多饮水、避免交叉感染。\", \"summary_th\": \"เด็กมีอาการไอมาประมาณ 1 สัปดาห์ ไอมากโดยเฉพาะตอนกลางคืน เริ่มแรกเป็นอาการไอแห้งๆ ต่อมามีเสมหะสีขาวข้น ร่วมกับอาการคัดจมูก จามบ้างเป็นครั้งคราว ไม่มีไข้ แพทย์เบื้องต้นสันนิษฐานว่าเป็นการติดเชื้อทางเดินหายใจส่วนบนหรือหลอดลมอักเสบระยะแรก แนะนำให้ตรวจนับเม็ดเลือด ทำการพ่นยา และแนะนำให้รับประทานอาหารรสอ่อน ดื่มน้ำมากๆ และหลีกเลี่ยงการติดเชื้อซ้ำซ้อน\"}\n",
    "]\n",
    "\n",
    "# Note: Prompt templates from the original script are not directly used for the Helsinki-NLP model,\n",
    "# as it's a direct translation model. We will feed the source Chinese text directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Hugging Face Model Setup\n",
    "MODEL_NAME = \"Helsinki-NLP/opus-mt-zh-th\"\n",
    "translator = None\n",
    "\n",
    "def initialize_translator():\n",
    "    global translator\n",
    "    if translator is None:\n",
    "        print(f\"[INFO] Initializing translator with model: {MODEL_NAME}...\")\n",
    "        try:\n",
    "            # Check for GPU availability\n",
    "            device = 0 if torch.cuda.is_available() else -1 # 0 for first GPU, -1 for CPU\n",
    "            if device == 0:\n",
    "                print(\"[INFO] CUDA (GPU) is available. Using GPU for translation.\")\n",
    "            else:\n",
    "                print(\"[INFO] CUDA (GPU) not available. Using CPU for translation.\")\n",
    "            \n",
    "            translator = pipeline(\"translation\", model=MODEL_NAME, device=device)\n",
    "            print(\"[INFO] Translator initialized successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to initialize translator: {e}\")\n",
    "            print(\"[INFO] Falling back to CPU if GPU initialization failed.\")\n",
    "            try:\n",
    "                translator = pipeline(\"translation\", model=MODEL_NAME, device=-1)\n",
    "                print(\"[INFO] Translator initialized successfully on CPU.\")\n",
    "            except Exception as e2:\n",
    "                print(f\"[ERROR] Failed to initialize translator on CPU: {e2}\")\n",
    "                translator = None # Ensure translator is None if all attempts fail\n",
    "    return translator\n",
    "\n",
    "# Call initialize_translator() once to load the model when the cell is run.\n",
    "# Subsequent calls will use the already loaded model.\n",
    "translator = initialize_translator() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc77fc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Helper function for translation\n",
    "def translate_text_hf(text_list, current_translator):\n",
    "    if not current_translator:\n",
    "        log_error(\"TranslationError\", -1, \"Translator not initialized.\")\n",
    "        if isinstance(text_list, list):\n",
    "            return [\"Translation unavailable\" for _ in text_list]\n",
    "        else:\n",
    "            return \"Translation unavailable\"\n",
    "    try:\n",
    "        # The pipeline can handle single string or list of strings\n",
    "        if isinstance(text_list, str): # single text\n",
    "             # Helsinki models expect src_lang and tgt_lang to be part of model name or config\n",
    "             # For opus-mt-zh-th, it's implicitly Chinese to Thai.\n",
    "            translation_result = current_translator(text_list)\n",
    "            return translation_result[0]['translation_text']\n",
    "        elif isinstance(text_list, list): # batch of texts\n",
    "            # Process in batches if the list is very large to avoid OOM, though pipeline handles some batching.\n",
    "            # For simplicity here, we pass the whole list. Consider actual batching for very large inputs.\n",
    "            translation_results = current_translator(text_list, batch_size=8) # Adjust batch_size as needed\n",
    "            return [res['translation_text'] for res in translation_results]\n",
    "    except Exception as e:\n",
    "        log_error(\"TranslationError\", -1, f\"Hugging Face API error: {e}\")\n",
    "        if isinstance(text_list, list):\n",
    "            return [f\"Error: {e}\" for _ in text_list]\n",
    "        else:\n",
    "            return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec83dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Logging and Metadata functions\n",
    "LOG_DIR = \"logs\"\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "LOG_FILE = os.path.join(LOG_DIR, f\"generate_dataset_colab_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE,\n",
    "    filemode='a',\n",
    "    format='%(asctime)s | %(levelname)s | %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "def log_error(error_type, sample_idx, message):\n",
    "    logging.error(f\"{error_type} | Sample: {sample_idx} | {message}\")\n",
    "    print(f\"[ERRORLOG] {error_type} | Sample: {sample_idx} | {message}\") # also print to console for Colab visibility\n",
    "\n",
    "def add_metadata(df):\n",
    "    \"\"\"Add metadata to the dataset\"\"\"\n",
    "    metadata = {\n",
    "        \"generator\": \"HuggingFace (Helsinki-NLP/opus-mt-zh-th)\",\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"license\": \"CC BY-SA-NC 4.0 (Dataset) / Apache 2.0 (Model)\",\n",
    "        \"generation_date\": pd.Timestamp.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"version\": \"2.0.0_colab_hf\",\n",
    "    }\n",
    "    for key, value in metadata.items():\n",
    "        df[f\"_metadata_{key}\"] = value\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b52801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: File and Path Utilities\n",
    "def random_id(prefix=\"D\"):\n",
    "    ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    rand = ''.join(pyrandom.choices(string.ascii_uppercase + string.digits, k=4))\n",
    "    return f\"{prefix}{rand}_{ts}\"\n",
    "\n",
    "def get_datasets_dir():\n",
    "    \"\"\"Return the datasets directory, create if not exists (Colab: /content/datasets/).\"\"\"\n",
    "    # In Colab, os.getcwd() is /content\n",
    "    datasets_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "    os.makedirs(datasets_dir, exist_ok=True)\n",
    "    return datasets_dir\n",
    "\n",
    "def unique_dataset_filename(base, ext, prefix=\"D\"):\n",
    "    ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    rand = ''.join(pyrandom.choices(string.ascii_uppercase + string.digits, k=4))\n",
    "    return f\"{base}_{prefix}{rand}_{ts}{ext}\"\n",
    "\n",
    "def save_dataset(df, output, file_format):\n",
    "    if not output:\n",
    "        datasets_dir = get_datasets_dir()\n",
    "        base = \"dataset\"\n",
    "        ext = \".\" + file_format\n",
    "        filename = unique_dataset_filename(base, ext)\n",
    "        output_path = os.path.join(datasets_dir, filename)\n",
    "    else:\n",
    "        # Ensure output path is absolute or relative to /content for Colab\n",
    "        if not os.path.isabs(output) and not output.startswith(\"/content\") :\n",
    "            output = os.path.join(\"/content\", output) # Default to /content if relative path given\n",
    "        \n",
    "        output_dir_user = os.path.dirname(output)\n",
    "        if output_dir_user and not os.path.exists(output_dir_user):\n",
    "            os.makedirs(output_dir_user, exist_ok=True) # Create user-specified directory\n",
    "            \n",
    "        if os.path.isdir(output):\n",
    "            base = \"dataset\"\n",
    "            ext = \".\" + file_format\n",
    "            filename = unique_dataset_filename(base, ext)\n",
    "            output_path = os.path.join(output, filename)\n",
    "        else:\n",
    "            base, ext_from_output = os.path.splitext(os.path.basename(output))\n",
    "            if not base:\n",
    "                base = \"dataset\"\n",
    "            # Use specified extension if provided, otherwise from format arg\n",
    "            ext = ext_from_output if ext_from_output else \".\" + file_format \n",
    "            prefix = base[0].upper() if base else \"D\"\n",
    "            # Use the filename as is if it's a full path with extension\n",
    "            if os.path.dirname(output) and ext_from_output : # User provided full path with extension\n",
    "                 output_path = output\n",
    "            else: # Auto generate filename or save in specified dir\n",
    "                filename = unique_dataset_filename(base, ext, prefix)\n",
    "                output_dir = os.path.dirname(output) or get_datasets_dir()\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    print(f\"[INFO] Attempting to save dataset to: {output_path}\")\n",
    "    if file_format == 'csv':\n",
    "        df.to_csv(output_path, index=False)\n",
    "    elif file_format == 'json':\n",
    "        df.to_json(output_path, orient='records', force_ascii=False, indent=2)\n",
    "    elif file_format == 'jsonl':\n",
    "        df.to_json(output_path, orient='records', force_ascii=False, lines=True)\n",
    "    elif file_format == 'txt':\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            for row in df.itertuples(index=False):\n",
    "                f.write(str(row) + '\n",
    "')\n",
    "    elif file_format == 'arrow' or file_format == 'parquet': # Parquet is a common use for arrow tables\n",
    "        try:\n",
    "            import pyarrow as pa\n",
    "            import pyarrow.parquet as pq\n",
    "            table = pa.Table.from_pandas(df)\n",
    "            pq.write_table(table, output_path)\n",
    "        except ImportError:\n",
    "            print(\"[ERROR] pyarrow library not found. Please install it to save in Arrow/Parquet format.\")\n",
    "            log_error(\"SaveDatasetError\", -1, \"pyarrow not installed for Arrow/Parquet format.\")\n",
    "            return # Exit if cannot save\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {file_format}\")\n",
    "    print(f\"[SUCCESS] Dataset saved: {output_path} ({len(df)} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Core Data Generation Logic\n",
    "\n",
    "def _process_dialogue_sample_hf(args_tuple):\n",
    "    i, topic, sample_data, current_translator, log_fn = args_tuple\n",
    "    source_text = sample_data[\"source\"]\n",
    "    target_text = translate_text_hf(source_text, current_translator)\n",
    "    \n",
    "    if \"Error:\" in target_text or \"Translation unavailable\" in target_text:\n",
    "        log_fn(\"TranslationFailure\", i, f\"Failed to translate. Source: {source_text}, Error: {target_text}\")\n",
    "        # Fallback to original sample target if provided, or use error message\n",
    "        target_text = sample_data.get(\"target\", target_text) \n",
    "        \n",
    "    return {\"context\": sample_data[\"context\"], \"source\": source_text, \"target\": target_text, \"original_index\": i}\n",
    "\n",
    "def generate_dialogue_dataset_hf(n_samples=100, seed=42, current_translator=None):\n",
    "    \"\"\"Generate dialogue dataset using Hugging Face model\"\"\"\n",
    "    if not current_translator:\n",
    "        print(\"[ERROR] Translator not available for dialogue generation.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    random.seed(seed)\n",
    "    print(f\"[INFO] Creating prompt combinations for {n_samples} dialogue samples...\")\n",
    "    \n",
    "    all_prompt_combinations = []\n",
    "    for topic in MEDICAL_TOPICS:\n",
    "        for sample in DIALOGUE_SAMPLES:\n",
    "            all_prompt_combinations.append((topic, sample))\n",
    "    \n",
    "    if not all_prompt_combinations:\n",
    "        print(\"[ERROR] No dialogue samples or medical topics defined.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    selected_combinations = []\n",
    "    if n_samples <= len(all_prompt_combinations):\n",
    "        selected_combinations = random.sample(all_prompt_combinations, n_samples)\n",
    "    else:\n",
    "        selected_combinations = all_prompt_combinations.copy()\n",
    "        remaining = n_samples - len(all_prompt_combinations)\n",
    "        combo_usage = {i: 1 for i in range(len(all_prompt_combinations))} \n",
    "        all_indices = list(range(len(all_prompt_combinations)))\n",
    "        for _ in range(remaining):\n",
    "            min_usage = min(combo_usage.values())\n",
    "            least_used_indices = [idx for idx, count in combo_usage.items() if count == min_usage]\n",
    "            selected_idx = random.choice(least_used_indices if least_used_indices else all_indices) # Fallback if all used equally\n",
    "            selected_combinations.append(all_prompt_combinations[selected_idx])\n",
    "            combo_usage[selected_idx] += 1\n",
    "            \n",
    "    tasks_args = []\n",
    "    for i, (topic, sample) in enumerate(selected_combinations):\n",
    "        tasks_args.append((i, topic, sample, current_translator, log_error))\n",
    "    \n",
    "    print(f\"[INFO] Created {len(tasks_args)} dialogue tasks.\")\n",
    "    \n",
    "    data = []\n",
    "    # Process tasks (simple loop, consider batching for HF pipeline for better performance)\n",
    "    # The HF pipeline itself can handle batching if a list of strings is passed.\n",
    "    # Here, _process_dialogue_sample_hf translates one by one.\n",
    "    source_texts_batch = [task_arg[2][\"source\"] for task_arg in tasks_args]\n",
    "    translated_texts_batch = translate_text_hf(source_texts_batch, current_translator)\n",
    "    \n",
    "    for i, task_arg_tuple in enumerate(tqdm(tasks_args, total=len(tasks_args), desc=\"Generating Dialogue Samples\")):\n",
    "        idx, topic, sample_data, _, _ = task_arg_tuple\n",
    "        target_text = translated_texts_batch[i]\n",
    "        if \"Error:\" in target_text or \"Translation unavailable\" in target_text:\n",
    "            log_error(\"TranslationFailure\", idx, f\"Failed to translate. Source: {sample_data[\"source\"]}, Error: {target_text}\")\n",
    "            target_text = sample_data.get(\"target\", target_text) \n",
    "        data.append({\"context\": sample_data[\"context\"], \"source\": sample_data[\"source\"], \"target\": target_text})\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    df = add_metadata(df)\n",
    "    return df\n",
    "\n",
    "def generate_qa_dataset_hf(n_samples=100, seed=42, current_translator=None):\n",
    "    \"\"\"Generate QA dataset using Hugging Face model\"\"\"\n",
    "    if not current_translator:\n",
    "        print(\"[ERROR] Translator not available for QA generation.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    data = []\n",
    "    random.seed(seed)\n",
    "    \n",
    "    if not QA_SAMPLES:\n",
    "        print(\"[ERROR] No QA_SAMPLES defined.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    for i in tqdm(range(n_samples), desc=\"Generating QA Samples\")):\n",
    "        sample = QA_SAMPLES[i % len(QA_SAMPLES)]\n",
    "        question_zh = sample[\"question\"]\n",
    "        answer_zh = sample[\"answer\"]\n",
    "        \n",
    "        try:\n",
    "            translations = translate_text_hf([question_zh, answer_zh], current_translator)\n",
    "            question_th = translations[0]\n",
    "            answer_th = translations[1]\n",
    "            \n",
    "            if \"Error:\" in question_th or \"Translation unavailable\" in question_th:\n",
    "                log_error(\"TranslationFailure\", i, f\"Q-Trans fail: {question_zh} -> {question_th}\")\n",
    "                question_th = sample.get(\"q_th\", question_th) # Fallback\n",
    "            if \"Error:\" in answer_th or \"Translation unavailable\" in answer_th:\n",
    "                log_error(\"TranslationFailure\", i, f\"A-Trans fail: {answer_zh} -> {answer_th}\")\n",
    "                answer_th = sample.get(\"a_th\", answer_th) # Fallback\n",
    "                \n",
    "        except Exception as e:\n",
    "            log_error(\"HF_API_Error_QA\", i, str(e))\n",
    "            question_th = sample.get(\"q_th\", f\"Error: {e}\")\n",
    "            answer_th = sample.get(\"a_th\", f\"Error: {e}\")\n",
    "        \n",
    "        data.append({\n",
    "            \"context\": sample[\"context\"],\n",
    "            \"question_zh\": question_zh,\n",
    "            \"answer_zh\": answer_zh,\n",
    "            \"question_th\": question_th,\n",
    "            \"answer_th\": answer_th\n",
    "        })\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    df = add_metadata(df)\n",
    "    return df\n",
    "\n",
    "def generate_reasoning_dataset_hf(n_samples=100, seed=42, current_translator=None):\n",
    "    \"\"\"Generate medical reasoning QA dataset using Hugging Face model\"\"\"\n",
    "    if not current_translator:\n",
    "        print(\"[ERROR] Translator not available for reasoning generation.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    data = []\n",
    "    random.seed(seed)\n",
    "    if not MEDICAL_REASONING_SAMPLES:\n",
    "        print(\"[ERROR] No MEDICAL_REASONING_SAMPLES defined.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    for i in tqdm(range(n_samples), desc=\"Generating Reasoning Samples\")):\n",
    "        sample = MEDICAL_REASONING_SAMPLES[i % len(MEDICAL_REASONING_SAMPLES)]\n",
    "        question_zh = sample[\"question\"]\n",
    "        answer_zh = sample[\"answer\"]\n",
    "        try:\n",
    "            translations = translate_text_hf([question_zh, answer_zh], current_translator)\n",
    "            question_th = translations[0]\n",
    "            answer_th = translations[1]\n",
    "            \n",
    "            if \"Error:\" in question_th or \"Translation unavailable\" in question_th:\n",
    "                log_error(\"TranslationFailure\", i, f\"Q-Trans fail: {question_zh} -> {question_th}\")\n",
    "                question_th = sample.get(\"q_th\", question_th)\n",
    "            if \"Error:\" in answer_th or \"Translation unavailable\" in answer_th:\n",
    "                log_error(\"TranslationFailure\", i, f\"A-Trans fail: {answer_zh} -> {answer_th}\")\n",
    "                answer_th = sample.get(\"a_th\", answer_th)\n",
    "                \n",
    "        except Exception as e:\n",
    "            log_error(\"HF_API_Error_Reasoning\", i, str(e))\n",
    "            question_th = sample.get(\"q_th\", f\"Error: {e}\")\n",
    "            answer_th = sample.get(\"a_th\", f\"Error: {e}\")\n",
    "            \n",
    "        data.append({\n",
    "            \"context\": sample[\"context\"],\n",
    "            \"question_zh\": question_zh,\n",
    "            \"answer_zh\": answer_zh,\n",
    "            \"question_th\": question_th,\n",
    "            \"answer_th\": answer_th\n",
    "        })\n",
    "    df = pd.DataFrame(data)\n",
    "    df = add_metadata(df)\n",
    "    return df\n",
    "\n",
    "def generate_summarization_dataset_hf(n_samples=100, seed=42, current_translator=None):\n",
    "    \"\"\"Generate summarization dataset by translating Chinese summaries using Hugging Face model\"\"\"\n",
    "    if not current_translator:\n",
    "        print(\"[ERROR] Translator not available for summarization generation.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    data = []\n",
    "    random.seed(seed)\n",
    "    if not SUMMARIZATION_SAMPLES:\n",
    "        print(\"[ERROR] No SUMMARIZATION_SAMPLES defined.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    for i in tqdm(range(n_samples), desc=\"Generating Summarization Samples\")):\n",
    "        sample = SUMMARIZATION_SAMPLES[i % len(SUMMARIZATION_SAMPLES)]\n",
    "        summary_zh = sample[\"summary_zh\"]\n",
    "        try:\n",
    "            summary_th = translate_text_hf(summary_zh, current_translator)\n",
    "            if \"Error:\" in summary_th or \"Translation unavailable\" in summary_th:\n",
    "                log_error(\"TranslationFailure\", i, f\"Summary-Trans fail: {summary_zh} -> {summary_th}\")\n",
    "                summary_th = sample.get(\"summary_th\", summary_th) # Fallback\n",
    "        except Exception as e:\n",
    "            log_error(\"HF_API_Error_Summarization\", i, str(e))\n",
    "            summary_th = sample.get(\"summary_th\", f\"Error: {e}\")\n",
    "            \n",
    "        data.append({\n",
    "            \"context\": sample[\"context\"],\n",
    "            \"summary_zh\": summary_zh,\n",
    "            \"summary_th\": summary_th\n",
    "        })\n",
    "    df = pd.DataFrame(data)\n",
    "    df = add_metadata(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00847355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Main Script Utilities\n",
    "def print_ascii_banner():\n",
    "    banner = r'''\n",
    "    ▒███████▒ ▒█████   ███▄ ▄███▓ ▄▄▄▄    ██▓▄▄▄█████▓\n",
    "    ▒ ▒ ▒ ▄▀░▒██▒  ██▒▓██▒▀█▀ ██▒▓█████▄ ▓██▒▓  ██▒ ▓▒\n",
    "    ░ ▒ ▄▀▒░ ▒██░  ██▒▓██    ▓██░▒██▒ ▄██▒██▒▒ ▓██░ ▒░\n",
    "      ▄▀▒   ░▒██   ██░▒██    ▒██ ▒██░█▀  ░██░░ ▓██▓ ░ \n",
    "    ▒███████▒░ ████▓▒░▒██▒   ░██▒░▓█  ▀█▓░██░  ▒██▒ ░ \n",
    "    ░▒▒ ▓░▒░▒░ ▒░▒░▒░ ░ ▒░   ░  ░░▒▓███▀▒░▓    ▒ ░░   \n",
    "    ░░▒ ▒ ░ ▒  ░ ▒ ▒░ ░  ░      ░▒░▒   ░  ▒ ░    ░    \n",
    "    ░ ░ ░ ░ ░░ ░ ░ ▒  ░      ░    ░    ░  ▒ ░  ░      \n",
    "      ░ ░        ░ ░         ░    ░       ░       ░    \n",
    "    ░                                  ░    ░                                                      \n",
    "\n",
    "   Medical Dialogue Machine Translation (Chinese→Thai) - Colab HF Version\n",
    "            Developer by JonusNattapong/zombit (Original Script)\n",
    "         Powered by Hugging Face Helsinki-NLP Model\n",
    "        CC BY-SA-NC 4.0 (Dataset) | https://github.com/JonusNattapong/MedMT\n",
    "'''\n",
    "    print(banner)\n",
    "\n",
    "def auto_batch_size(n_samples):\n",
    "    \"\"\"Determine batch size for processing samples (not model inference batch)\"\"\"\n",
    "    if n_samples >= 10000: return 200 # Reduced for potentially slower local processing\n",
    "    elif n_samples >= 5000: return 100\n",
    "    elif n_samples >= 1000: return 50\n",
    "    elif n_samples >= 500: return 20\n",
    "    elif n_samples >= 100: return 10\n",
    "    else: return 5\n",
    "\n",
    "def recommend_format(mode, output, n_samples):\n",
    "    ext = \"\"\n",
    "    if output is not None:\n",
    "        ext = os.path.splitext(output)[1].lower()\n",
    "    if ext in [\".csv\", \".json\", \".jsonl\", \".txt\", \".arrow\", \".parquet\"]:\n",
    "        return ext.lstrip(\".\")\n",
    "    # Simplified recommendations for Colab\n",
    "    if n_samples > 50000 and mode != \"pretrain\": return \"parquet\" # Parquet is good for large tabular data\n",
    "    if mode == \"pretrain\": return \"txt\"\n",
    "    return \"csv\" # Default to CSV for smaller/general cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2a285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Argparse and Main function\n",
    "def main_colab(args_dict):\n",
    "    print_ascii_banner()\n",
    "    \n",
    "    # Convert dict to Namespace-like object for compatibility with original parser access\n",
    "    class ArgsNamespace:\n",
    "        def __init__(self, **kwargs):\n",
    "            self.__dict__.update(kwargs)\n",
    "    args = ArgsNamespace(**args_dict)\n",
    "    \n",
    "    # Ensure translator is initialized (it's global, set in Cell 4)\n",
    "    global translator\n",
    "    if translator is None:\n",
    "        print(\"[ERROR] Translator model could not be initialized. Please check Cell 4 output.\")\n",
    "        return\n",
    "        \n",
    "    recommended_format_val = recommend_format(args.mode, args.output, args.n_samples)\n",
    "    if args.format is None:\n",
    "        args.format = recommended_format_val\n",
    "        print(f\"[INFO] Auto-selected output format: {args.format.upper()} (recommended for mode '{args.mode}')\")\n",
    "    elif args.format != recommended_format_val:\n",
    "        print(f\"[INFO] You selected format '{args.format.upper()}'. Recommended format for mode '{args.mode}' is '{recommended_format_val.upper()}'.\")\n",
    "\n",
    "    # Adjust output path for Colab if it's not absolute\n",
    "    output_file = args.output\n",
    "    if output_file and not os.path.isabs(output_file) and not output_file.startswith(\"/content\"):\n",
    "        output_file = os.path.join(\"/content/datasets\", os.path.basename(output_file) if os.path.basename(output_file) else unique_dataset_filename(\"dataset\", \".\" + args.format, args.mode[0].upper()))\n",
    "        print(f\"[INFO] Adjusted output path for Colab: {output_file}\")\n",
    "    elif not output_file: # If output is None, generate a name in /content/datasets/\n",
    "        datasets_dir = get_datasets_dir()\n",
    "        base = args.mode + \"_dataset\"\n",
    "        ext = \".\" + args.format\n",
    "        output_file = os.path.join(datasets_dir, unique_dataset_filename(base, ext, args.mode[0].upper()))\n",
    "        print(f\"[INFO] Output file will be automatically named and saved to: {output_file}\")\n",
    "        \n",
    "    args.output = output_file # Update args with potentially modified path\n",
    "    \n",
    "    print(f\"[INFO] Mode: {args.mode} | Samples: {args.n_samples} | Output: {args.output} | Format: {args.format}\")\n",
    "    print(f\"[INFO] Using Hugging Face model {MODEL_NAME} for translation.\")\n",
    "    print(\"[INFO] Generating dataset... (this may take a while for large datasets)\" )\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    generator_func = None\n",
    "    if args.mode == 'dialogue':\n",
    "        generator_func = generate_dialogue_dataset_hf\n",
    "    elif args.mode == 'qa':\n",
    "        generator_func = generate_qa_dataset_hf\n",
    "    elif args.mode == 'reasoning':\n",
    "        generator_func = generate_reasoning_dataset_hf\n",
    "    elif args.mode == 'summarization':\n",
    "        generator_func = generate_summarization_dataset_hf\n",
    "    else:\n",
    "        print(f\"[ERROR] Unknown mode: {args.mode}\")\n",
    "        return\n",
    "\n",
    "    # Batching for generation (not model inference batching, which is handled by pipeline or translate_text_hf)\n",
    "    # This outer batching is to manage memory for large n_samples and allow periodic saving if implemented.\n",
    "    # For now, it generates all 'n_samples' in one go by the generator function.\n",
    "    # The original script's batching loop was more about calling the generator multiple times for smaller chunks.\n",
    "    # Here, we call the generator once with the total n_samples.\n",
    "    \n",
    "    # The generator functions now take current_translator as an argument\n",
    "    df_all = generator_func(n_samples=args.n_samples, seed=42, current_translator=translator) \n",
    "    \n",
    "    if df_all.empty:\n",
    "        print(\"[ERROR] No data generated. Please check logs and configurations.\")\n",
    "        return\n",
    "        \n",
    "    print(f\"[INFO] Saving dataset to {args.output} as {args.format.upper()} ...\")\n",
    "    save_dataset(df_all, args.output, args.format)\n",
    "    # print(f\"[SUCCESS] Dataset saved. ({len(df_all)} samples)\") # save_dataset already prints this\n",
    "    print(\"[INFO] Dataset is licensed under CC BY-SA-NC 4.0 (https://creativecommons.org/licenses/by-nc-sa/4.0/)\" )\n",
    "    print(f\"[INFO] Log file saved to: {LOG_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc14a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Colab Parameter Setup and Execution Example\n",
    "\n",
    "# --- CONFIGURE YOUR PARAMETERS HERE ---\n",
    "colab_args = {\n",
    "    \"output\": None,  # Set to a specific path like '/content/my_dataset.csv' or None for auto-naming in /content/datasets/\n",
    "    \"n_samples\": 10,      # Number of samples to generate\n",
    "    \"mode\": \"dialogue\",    # 'dialogue', 'qa', 'reasoning', 'summarization'\n",
    "    \"format\": None       # 'csv', 'json', 'jsonl', 'txt', 'arrow'/'parquet', or None for auto-selection\n",
    "}\n",
    "# ---\n",
    "\n",
    "# Ensure the translator is loaded before running main\n",
    "if translator is None:\n",
    "    print(\"[INFO] Translator was not loaded. Attempting to initialize now...\")\n",
    "    translator = initialize_translator() # Attempt to initialize if not already\n",
    "\n",
    "if translator: # Proceed only if translator is available\n",
    "    print(f\"Executing with parameters: {colab_args}\")\n",
    "    main_colab(colab_args)\n",
    "else:\n",
    "    print(\"[FATAL ERROR] Translator could not be initialized. Cannot proceed with dataset generation. Check previous cell outputs for errors.\")\n",
    "\n",
    "# Example of generating a different type of dataset:\n",
    "# colab_args_qa = {\n",
    "#     \"output\": \"/content/datasets/qa_colab_output.jsonl\",\n",
    "#     \"n_samples\": 5,\n",
    "#     \"mode\": \"qa\",\n",
    "#     \"format\": \"jsonl\"\n",
    "# }\n",
    "# if translator:\n",
    "#     print(f\"Executing QA generation with parameters: {colab_args_qa}\")\n",
    "#     main_colab(colab_args_qa)\n",
    "# else:\n",
    "#     print(\"[FATAL ERROR] Translator could not be initialized for QA example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8220d",
   "metadata": {},
   "source": [
    "## Notes on Usage and Potential Improvements:\n",
    "\n",
    "1.  **Model Performance**: `Helsinki-NLP/opus-mt-zh-th` is a general-purpose Chinese-to-Thai translation model. Its performance on highly specialized medical terminology might vary. For production use, fine-tuning on a medical domain-specific corpus could improve results.\n",
    "2.  **Processing Speed**: Translation, especially on CPU, can be slow for large datasets. The Hugging Face `pipeline` does some internal batching. For very large `n_samples`, consider running this on a Colab session with GPU acceleration (check `Runtime > Change runtime type`).\n",
    "3.  **Error Handling**: The script includes basic error handling for translation failures, falling back to original English samples or error messages. Review the generated `LOG_FILE` for any issues.\n",
    "4.  **Dataset Diversity**: The original script had mechanisms for prompt diversification for the DeepSeek LLM. For direct translation models, diversity mainly comes from the model's training. To increase diversity, one might consider:\n",
    "    *   Using multiple different open-source translation models.\n",
    "    *   Employing back-translation techniques (though this adds complexity).\n",
    "5.  **Batching for Translation**: In `generate_dialogue_dataset_hf`, source texts are now batched before being sent to `translate_text_hf`. The `translate_text_hf` function itself uses the Hugging Face pipeline which can handle batches. You can adjust `batch_size` in `translate_text_hf` if needed, though the pipeline's default might be optimal.\n",
    "6.  **Resource Limits**: Colab has usage limits. For very large datasets (e.g., >50k samples), you might need to run the script in multiple sessions or use a more robust environment.\n",
    "7.  **Saving Output**: Datasets are saved in your Colab environment (typically under `/content/datasets/` if no specific path is given). Remember to download them before your Colab session ends, or mount Google Drive to save them persistently.\n",
    "    ```python\n",
    "    # To mount Google Drive (run in a new cell if needed)\n",
    "    # from google.colab import drive\n",
    "    # drive.mount('/content/drive')\n",
    "    # Then you can set output paths like '/content/drive/MyDrive/my_dataset.csv'\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
